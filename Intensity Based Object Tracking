import sys
import os
import cv2
import numpy as np
import random
from matplotlib import pyplot as plt
from IPython.display import clear_output
%matplotlib inline

# Setup for object tracking

if not os.path.isdir(os.path.join(os.getcwd(), 'frames')):
    os.mkdir("frames")
else:
    print('frames already exists')

if not os.path.isdir(os.path.join(os.getcwd(), 'composite')):
    os.mkdir("composite")
else:
    print('composite already exists')
    
framenumber = 0
framectr = 0
omovie = cv2.VideoCapture('ping_pang.mov')
frame_height = omovie.get(cv2.CAP_PROP_FRAME_HEIGHT)
frame_width = omovie.get(cv2.CAP_PROP_FRAME_WIDTH)

# Extract the frames from original video
while(1):
    ret, frame = omovie.read()
    if not ret:
        break
    print('Extracting: %d' % framenumber)
    clear_output(wait=True)
    cv2.imwrite('frames/%d.tif' % framenumber, frame)
    framenumber += 1
omovie.release()


'''
    Find the object coordinate by averaging the foreground coordinates
    - Function Input: 
            -         frame:   numpy array, the frame to be processed
            -     threshold:           int, the threshold to segment the object

    - Function Output:
            - [object_x, object_y]: the coordinate of the object in the frame
'''
def findObj(frame, threshold):
    ############# TO DO #############

    return 


# Draw a circle on the image
def drawbox(frame, centerx, centery, radius, color):
    for y in range(centerx - radius, centerx + radius):
        for x in range(centery - radius, centery + radius):
            cx = 0 if x < 0 else frame.shape[0]-1 if x > frame.shape[0] - 1 else x
            cy = 0 if y < 0 else frame.shape[1]-1 if y > frame.shape[1] - 1 else y
            for i in range(3):
                frame[cx][cy][i] = color[i]
    return frame

framectr = framenumber - 1
process_frame = 0

foreground = 250 # Foreground Threshold for Segmentation
# Store the coordinates found by intensity thresholding
coordListX = list()
coordListY = list()

while process_frame <= framectr:
    oframe = cv2.imread('frames/%d.tif' % process_frame)
    print('Processing frame: %d, overall progress: %.2f %%' % (process_frame, process_frame/framectr*100))
    clear_output(wait=True)
    
    # Change frame to grey scale
    gframe = oframe.copy() # Grey scaled frame

    # Load the saved frames sequentially
    height = None
    width = None
    for y in range(gframe.shape[1]):
        for x in range(gframe.shape[0]):
            # Convert to gray scale
            g = 0.212671 * gframe[x][y][2] + 0.715160 * gframe[x][y][1] + 0.072169 * gframe[x][y][0]

            # Convert to binary
            for i in range(3):
                if g > foreground:
                    gframe[x][y][i] = 255
                else:
                    gframe[x][y][i] = 0

    # Get the initial state (object coordinates) from binary segmentation
    coord = findObj(gframe, 128) # coord is the centre of mass
                                 # coord[0] : y column
                                 # coord[1] : x row
            
    # Draw a red dot in the centre of the segmented object
    oframe = drawbox(oframe, int(coord[1]), int(coord[0]), 5, (0, 0, 255))
    gframe = drawbox(gframe, int(coord[1]), int(coord[0]), 5, (0, 0, 255))
    combined_img = np.hstack((oframe, gframe))
    ####################################### TODO ###############################################
    # 1. You need to perform the object segmentation results on 'gframe'                       #
    # 2. You need to display the object moving trajectory on 'oframe'                          #
    # 3. You need to display a text to determine whether the object is found or not in a frame #
    # 4. Please see the lab sheet for reference                                                #
    
    

    ####################################### END ################################################
    cv2.imwrite('composite/composite%d.tif' % process_frame, combined_img)
    if cv2.waitKey(30) & 0xff == ord('q'):
        break
    process_frame += 1
